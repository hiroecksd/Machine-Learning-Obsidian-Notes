# Markov Process/Chain
A **Markov process** is a memoryless random process. It is a process for which predictions can be made regarding future outcomes based solely on its present state and most importantly such prediction are just as good as the ones that could be made knowing processes full history. Conditional on the present state of the system, and past states are independent. Because we have not formally defined what we mean by dynamics/transitions I will do it here. A **transition** are the changes of state of the system. We define $S$ as a finite set of states with $s \in S$. Then we can define $P$ as the transition or dynamics model which specifies $$ p(s_{t + 1} = s' | s_{t} = s)$$ One thing you should know that if there is no rewards, there will be no actions. Given that we have a finite number ($N$) of states, the transition model $P$ can be expressed as a matrix: $$ P = \begin{pmatrix} P(s_{1} | s_{1}) & \cdots & P(s_{N} | s_{1}) \\ \vdots & \ddots & \vdots \\ P(S_{1} | s_{N}) & \cdots & P(s_{N} | s_{N}) \end{pmatrix} $$ 